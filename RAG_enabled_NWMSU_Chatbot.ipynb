{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SridharCheppala/PrepBot/blob/main/RAG_enabled_NWMSU_Chatbot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ji09xLvKqBBd"
      },
      "source": [
        "<p> ################################################################## </p>\n",
        "<p>#&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;#\n",
        "<p> # This source code is adopted from Tomaz and modified for NWMSU chatbot application  &nbsp; #</p>\n",
        "<p>#&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;#\n",
        "<p></p>\n",
        "<p></p>\n",
        "<p> ################################################################## </p>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zqgaHIIWAv0E"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y8W6QNR3xzEO",
        "outputId": "70791ecd-eb05-4fee-fcd1-1168bdb68652"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n",
            "/content/gdrive/My Drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "%cd gdrive/My Drive"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_5jQBSpUA1YJ"
      },
      "source": [
        "Requirements:\n",
        "\n",
        "1. **LangChain**: A framework for developing applications powered by language models.\n",
        "2. **LangChain-Community**: A collaborative space for sharing resources, tools, and discussions related to LangChain.\n",
        "3. **LangChain-OpenAI**: A LangChain extension providing integration with OpenAI's language models.\n",
        "4. **LangChain-Experimental**: A repository for experimental features and prototypes within the LangChain ecosystem.\n",
        "5. **Neo4j**: A graph database management system designed for handling and querying connected data.\n",
        "6. **tiktoken**: A library for tokenizing text, commonly used with language models to preprocess input and output.\n",
        "7. **yfiles_jupyter_graphs**: A library for creating and visualizing graphs and network diagrams in Jupyter notebooks.\n",
        "8. **Streamlit**: An open-source framework for building interactive, web-based applications using Python.\n",
        "9. **Localtunnel**: A tool that allows you to expose your local web server to the internet via a secure tunnel.\n",
        "10. **CTransformers** : A python wrapper for transfomer based models with essential configurations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_e8mFtjUpsf-",
        "outputId": "41f7ebcb-0dc3-4803-a92c-f24df3fb254d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m59.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.4/62.4 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.2/209.2 kB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m312.3/312.3 kB\u001b[0m \u001b[31m22.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m61.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.7/15.7 MB\u001b[0m \u001b[31m58.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.8/9.8 MB\u001b[0m \u001b[31m92.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m95.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m59.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "%pip install --upgrade --quiet  langchain langchain-community langchain-openai langchain-experimental neo4j tiktoken yfiles_jupyter_graphs streamlit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uFTCrVRKSfls",
        "outputId": "0b239924-a989-4069-9081-fcae86ffaed6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ctransformers\n",
            "  Downloading ctransformers-0.2.27-py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.11/dist-packages (from ctransformers) (0.30.2)\n",
            "Requirement already satisfied: py-cpuinfo<10.0.0,>=9.0.0 in /usr/local/lib/python3.11/dist-packages (from ctransformers) (9.0.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub->ctransformers) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub->ctransformers) (2025.3.2)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub->ctransformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub->ctransformers) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub->ctransformers) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub->ctransformers) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub->ctransformers) (4.13.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub->ctransformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub->ctransformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub->ctransformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub->ctransformers) (2025.1.31)\n",
            "Downloading ctransformers-0.2.27-py3-none-any.whl (9.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.9/9.9 MB\u001b[0m \u001b[31m32.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: ctransformers\n",
            "Successfully installed ctransformers-0.2.27\n"
          ]
        }
      ],
      "source": [
        "pip install ctransformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wQpoIlvoWU-Y",
        "outputId": "30df7d46-cc7e-40f5-cceb-ee24d8a25b6f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: neo4j in /usr/local/lib/python3.11/dist-packages (5.28.1)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.11/dist-packages (from neo4j) (2025.2)\n"
          ]
        }
      ],
      "source": [
        "pip install neo4j"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EKRc3oenyXvO",
        "outputId": "2a7a8743-7920-442b-82eb-1b99dee54533"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K⠇\u001b[1G\u001b[0K⠏\u001b[1G\u001b[0K⠋\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K⠇\u001b[1G\u001b[0K⠏\u001b[1G\u001b[0K⠋\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K⠇\u001b[1G\u001b[0K⠏\u001b[1G\u001b[0K⠋\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K⠇\u001b[1G\u001b[0K⠏\u001b[1G\u001b[0K⠋\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K⠇\u001b[1G\u001b[0K⠏\u001b[1G\u001b[0K⠋\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K⠇\u001b[1G\u001b[0K⠏\u001b[1G\u001b[0K\n",
            "up to date, audited 23 packages in 7s\n",
            "\u001b[1G\u001b[0K⠏\u001b[1G\u001b[0K\n",
            "\u001b[1G\u001b[0K⠏\u001b[1G\u001b[0K3 packages are looking for funding\n",
            "\u001b[1G\u001b[0K⠏\u001b[1G\u001b[0K  run `npm fund` for details\n",
            "\u001b[1G\u001b[0K⠏\u001b[1G\u001b[0K\n",
            "2 \u001b[31m\u001b[1mhigh\u001b[22m\u001b[39m severity vulnerabilities\n",
            "\n",
            "To address all issues (including breaking changes), run:\n",
            "  npm audit fix --force\n",
            "\n",
            "Run `npm audit` for details.\n",
            "\u001b[1G\u001b[0K⠏\u001b[1G\u001b[0K"
          ]
        }
      ],
      "source": [
        "!npm install localtunnel"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LQtND_fzFRNI"
      },
      "source": [
        "The provided code imports several components from different libraries, each serving a specific purpose. The `RunnableBranch`, `RunnableLambda`, `RunnableParallel`, and `RunnablePassthrough` from LangChain Core are utilities for creating complex workflows involving branching logic, function definitions, parallel execution, and straightforward data passing. For crafting prompts, `ChatPromptTemplate` and `PromptTemplate` are used to design structured inputs for language models.\n",
        "\n",
        "The `BaseModel` and `Field` from Pydantic assist in data validation and configuration, while typing utilities like `Tuple`, `List`, and `Optional` are used for type hinting in Python code. The message classes `AIMessage` and `HumanMessage` define interactions between an AI and a user. The `StrOutputParser` is employed for converting outputs into string format.\n",
        "\n",
        "The `os` module provides a way to interact with the operating system, and `Neo4jGraph` facilitates working with Neo4j databases. `TokenTextSplitter` helps in breaking down text into manageable tokens, essential for language processing. `ChatOpenAI` enables communication with OpenAI's chat models, and `LLMGraphTransformer` is used for transforming graph data with language models. For database interaction, `GraphDatabase` connects with Neo4j, and `GraphWidget` allows for the creation and visualization of graphs in Jupyter notebooks.\n",
        "\n",
        "Further, `Neo4jVector` supports storing and retrieving embeddings in Neo4j, while `OpenAIEmbeddings` provides tools for generating embeddings from OpenAI models. The `remove_lucene_chars` function cleans text by removing specific characters, ensuring data is properly formatted for Neo4j. Lastly, `ConfigurableField` allows for configurable data fields within a runnable, aiding in the customization of workflows."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "n5jFoh3cqFfH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "666fd86a-19aa-4f77-c532-bcfe86f21075"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py:3553: LangChainDeprecationWarning: As of langchain-core 0.3.0, LangChain uses pydantic v2 internally. The langchain_core.pydantic_v1 module was a compatibility shim for pydantic v1, and should no longer be used. Please update the code to import from Pydantic directly.\n",
            "\n",
            "For example, replace imports like: `from langchain_core.pydantic_v1 import BaseModel`\n",
            "with: `from pydantic import BaseModel`\n",
            "or the v1 compatibility namespace if you are working in a code base that has not been fully upgraded to pydantic 2 yet. \tfrom pydantic.v1 import BaseModel\n",
            "\n",
            "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
          ]
        }
      ],
      "source": [
        "# %%writefile main.py\n",
        "\n",
        "from langchain_core.runnables import (\n",
        "    RunnableBranch,\n",
        "    RunnableLambda,\n",
        "    RunnableParallel,\n",
        "    RunnablePassthrough,\n",
        ")\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.prompts.prompt import PromptTemplate\n",
        "from langchain_core.pydantic_v1 import BaseModel, Field\n",
        "from typing import Tuple, List, Optional\n",
        "from langchain_core.messages import AIMessage, HumanMessage\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "import os\n",
        "from langchain_community.graphs import Neo4jGraph\n",
        "from langchain.text_splitter import TokenTextSplitter\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_experimental.graph_transformers import LLMGraphTransformer\n",
        "from neo4j import GraphDatabase\n",
        "from yfiles_jupyter_graphs import GraphWidget\n",
        "from langchain_community.vectorstores import Neo4jVector\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "from langchain_community.vectorstores.neo4j_vector import remove_lucene_chars\n",
        "from langchain_core.runnables import ConfigurableField, RunnableParallel, RunnablePassthrough\n",
        "\n",
        "\n",
        "try:\n",
        "  import google.colab\n",
        "  from google.colab import output\n",
        "  output.enable_custom_widget_manager()\n",
        "except:\n",
        "  pass\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-n8hzmiPGDkr"
      },
      "source": [
        "These lines of code set environment variables for accessing the OpenAI API and a Neo4j database:\n",
        "\n",
        "- `os.environ[\"OPENAI_API_KEY\"] = \"sk-....\"` sets the API key for accessing OpenAI's services.\n",
        "- `os.environ[\"NEO4J_URI\"] = \"bolt+s://d......databases.neo4j.io:7687\"` specifies the URI for connecting to the Neo4j database.\n",
        "- `os.environ[\"NEO4J_USERNAME\"] = \"usr\"` sets the username for the Neo4j database connection.\n",
        "- `os.environ[\"NEO4J_PASSWORD\"] = \"pwd\"` sets the password for the Neo4j database connection.\n",
        "\n",
        "These environment variables are crucial for securely storing sensitive information required for connecting to external services."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "u-x0sDvkzApK"
      },
      "outputs": [],
      "source": [
        "os.environ[\"OPENAI_API_KEY\"] = \"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\"#replace your OPEN_API key\n",
        "os.environ[\"NEO4J_URI\"] = \"neo4j+s://4e016907.databases.neo4j.io\"#NEO4J URL\n",
        "os.environ[\"NEO4J_USERNAME\"] = \"neo4j\" #NEO4J USERNAME\n",
        "os.environ[\"NEO4J_PASSWORD\"] = \"xdrgsXAbPcI3DY4Fkl7NKt51WaguG8k6ihDksSNA5ZM\"#NEO4J PASSWORD\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W3SvhzJ4GIM2"
      },
      "source": [
        "This instance, stored in the variable graph, can be used to interact with the Neo4j database. The Neo4jGraph class provides methods and functionalities to execute queries, retrieve data, and manipulate the graph database, facilitating seamless integration and operations within the LangChain framework."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "XwzkR_GOzArj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf730b3d-897d-4c40-f532-9c8ed869cf13"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-8-6e7385464d00>:1: LangChainDeprecationWarning: The class `Neo4jGraph` was deprecated in LangChain 0.3.8 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-neo4j package and should be used instead. To use it run `pip install -U :class:`~langchain-neo4j` and import as `from :class:`~langchain_neo4j import Neo4jGraph``.\n",
            "  graph = Neo4jGraph()\n"
          ]
        }
      ],
      "source": [
        "graph = Neo4jGraph()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iw1cepLUGWEM"
      },
      "source": [
        "This code snippet loads web pages from a list of URLs using the `WebBaseLoader` class from the `langchain_community.document_loaders` module:\n",
        "\n",
        "\n",
        "- **WebBaseLoader**: This class is used for loading web pages from URLs provided in a list. It likely uses web scraping techniques to retrieve the content from each URL.\n",
        "- **loader.requests_kwargs**: This line sets a keyword argument for the HTTP request made by the loader. `{'verify': False}` disables SSL certificate verification, which can be useful when dealing with self-signed certificates or testing environments.\n",
        "- **data = loader.load()**: This line executes the loading process, fetching the HTML content from the specified URLs and storing it in the `data` variable.\n",
        "\n",
        "This approach is helpful for gathering content from multiple web pages for further processing, such as natural language processing or content analysis, within the LangChain framework."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nfpW5QoAudoX",
        "outputId": "27b78fd1-d464-419f-d715-6b23a027f0cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_community.utils.user_agent:USER_AGENT environment variable not set, consider setting it to identify your requests.\n",
            "/usr/local/lib/python3.11/dist-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.geeksforgeeks.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.interviewbit.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.simplilearn.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.turing.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.turing.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'intellipaat.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.edureka.co'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.analyticsvidhya.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.interviewquery.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.springboard.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.ibm.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.ibm.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'builtin.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.geeksforgeeks.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'machinelearningmastery.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.sas.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.techtarget.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.expert.ai'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'towardsdatascience.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'ai.google'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'ai.google'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.kdnuggets.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.indeed.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'resources.workable.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.simplilearn.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.toptal.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.mygreatlearning.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from langchain_community.document_loaders import WebBaseLoader\n",
        "loader = WebBaseLoader([\"https://www.geeksforgeeks.org/top-50-software-engineering-interview-questions/\",\n",
        "    \"https://www.interviewbit.com/software-engineering-mcq/\",\n",
        "    \"https://www.simplilearn.com/tutorials/artificial-intelligence-tutorial/ai-interview-questions\",\n",
        "    \"https://www.turing.com/blog/top-ai-interview-questions-and-answers/\",\n",
        "    \"https://intellipaat.com/blog/interview-question/artificial-intelligence-interview-questions/\",\n",
        "    \"https://www.edureka.co/blog/interview-questions/artificial-intelligence-interview-questions/\",\n",
        "    \"https://www.analyticsvidhya.com/blog/2021/08/top-50-machine-learning-interview-questions/\",\n",
        "    \"https://www.interviewquery.com/interview-questions/machine-learning\",\n",
        "    \"https://www.springboard.com/blog/data-science/machine-learning-interview-questions/\",\n",
        "    \"https://www.ibm.com/cloud/learn/what-is-artificial-intelligence\",\n",
        "    \"https://builtin.com/artificial-intelligence\",\n",
        "    \"https://www.geeksforgeeks.org/machine-learning/\",\n",
        "    \"https://machinelearningmastery.com/\",\n",
        "    \"https://www.sas.com/en_us/insights/analytics/machine-learning.html\",\n",
        "    \"https://www.techtarget.com/searchenterpriseai/definition/artificial-intelligence-AI\",\n",
        "    \"https://www.expert.ai/blog/machine-learning-definition/\",\n",
        "    \"https://towardsdatascience.com/\",\n",
        "    \"https://ai.google/education/\",\n",
        "    \"https://www.kdnuggets.com/\",\n",
        "    \"https://www.indeed.com/career-advice/finding-a-job/machine-learning-engineer-job-description\",\n",
        "    \"https://resources.workable.com/artificial-intelligence-engineer-job-description\",\n",
        "    \"https://www.simplilearn.com/ai-engineer-job-description-article\",\n",
        "    \"https://www.toptal.com/machine-learning/job-description\",\n",
        "    \"https://www.mygreatlearning.com/blog/artificial-intelligence-career-path/\"\n",
        "                        ])\n",
        "loader.requests_kwargs = {'verify':False}\n",
        "data = loader.load()\n",
        "# print(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T4Fcg-eBv2AB",
        "outputId": "547d6ec6-f25e-487e-b616-cb2a52499f4f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6081"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "len(data[0].page_content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "fOWYO20aLVBL",
        "outputId": "c2b79e09-c0de-4a3b-bac9-f3553882c1b1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nPage not found | GeeksforGeeks\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "data[0].page_content[0:100]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LNSNunP2Gd2c"
      },
      "source": [
        "\n",
        "\n",
        "- **TokenTextSplitter**: This class is used to split text into chunks, typically to prepare it for processing by language models or other natural language processing tasks.\n",
        "- **text_splitter = TokenTextSplitter(chunk_size=512, chunk_overlap=24)**: Initializes an instance of `TokenTextSplitter` with a chunk size of 512 tokens and an overlap of 24 tokens between consecutive chunks.\n",
        "- **documents = text_splitter.split_documents(data)**: Splits the input `data` (presumably a collection of text documents) into chunks of the specified size and overlap, storing the resulting chunks in the `documents` variable.\n",
        "\n",
        "This approach is useful for breaking down large text documents or datasets into manageable pieces that can be processed more efficiently by downstream tasks or models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "WSBwTblIxmgO"
      },
      "outputs": [],
      "source": [
        "text_splitter = TokenTextSplitter(chunk_size=512, chunk_overlap=24)\n",
        "documents = text_splitter.split_documents(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dI5DbzHLezVX",
        "outputId": "9a9793dc-1745-482a-8f02-03a976c3775a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "page_content='\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Page not found | GeeksforGeeks\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Skip to content\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "CoursesDSA to DevelopmentGet IBM CertificationNewly Launched!Master Django FrameworkBecome AWS CertifiedFor Working ProfessionalsInterview 101: DSA & System DesignData Science Training ProgramJAVA Backend Development (Live)DevOps Engineering (LIVE)Data Structures & Algorithms in PythonFor StudentsPlacement Preparation CourseData Science (Live)Data Structure & Algorithm-Self Paced (C++/JAVA)Master Competitive Programming (Live)Full Stack Development with React & Node JS (Live)Full Stack DevelopmentData Science ProgramAll CoursesTutorialsData Structures & AlgorithmsML & Data ScienceInterview CornerProgramming LanguagesWeb DevelopmentCS SubjectsDevOps And LinuxSchool LearningPracticeBuild your AI AgentGfG 160Problem of the DayPractice Coding ProblemsGfG SDE SheetContestsAccenture Hackathon (Ending Soon!)GfG Weekly [Rated Contest]Job-A-Thon Hiring ChallengeAll Contests and Events\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "DSAPractice ProblemsPythonC C++JavaCoursesMachine LearningDevOpsWeb DevelopmentSystem DesignAptitudeProjects \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Sign In\n",
            "\n",
            "\n",
            "▲\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Whoops, that page is gone.\n",
            " While you're here, check out these popular recommendations  \n",
            " or search to explore more! \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "DSA Tutorial - Learn Data Structures and Algorithms - GeeksforGeeksJava Tutorial - Learn Java ProgrammingPython Tutorial | Learn Python Programming LanguageWeb Technology7 Different Ways to Take a Screenshot in Windows 10 - GeeksforGeeksEnumerate() in Python - GeeksforGeeksInsertion Sort Algorithm - GeeksforGeeksFull Stop Punctuation - Meaning, Usage and Examplesf-strings in Python - GeeksforGeeksWhat is OSI Model | 7 Layers ExplainedMerge Sort - Data Structure and Algorithms Tutorials - GeeksforGeeksBinary Search Algorithm - Iterative and Recursive Implementation - GeeksforGeeksQuick Sort - GeeksforG' metadata={'source': 'https://www.geeksforgeeks.org/top-50-software-engineering-interview-questions/', 'title': 'Page not found | GeeksforGeeks', 'language': 'en-US'}\n",
            "page_content='inary Search Algorithm - Iterative and Recursive Implementation - GeeksforGeeksQuick Sort - GeeksforGeeksASCII Values Alphabets ( A-Z, a-z & Special Character Table ) - GeeksforGeeksBubble Sort Algorithm - GeeksforGeeksPython map() functionHow to Download and Install the Google Play Store?Breadth First Search or BFS for a Graph - GeeksforGeeks200+ Core Java Interview Questions and Answers (2025)Find Shortest Paths from Source to all Vertices using Dijkstra’s AlgorithmSelection Sort - GeeksforGeeksSoftware Development Life Cycle (SDLC) - GeeksforGeeksPython Tkinter - GeeksforGeeksData Structures Tutorial - GeeksforGeeksPython Projects for Beginner to Advanced - GeeksforGeeksHow To Access WhatsApp Web Without PhonePython Dictionaries (with Examples)How to Read from a File in Python - GeeksforGeeksSQL Joins (Inner, Left, Right and Full Join)Introduction of ER Model - GeeksforGeeksPython Match Case Statement - GeeksforGeeksDepth First Search or DFS for a Graph - GeeksforGeeksDynamic Memory Allocation in C using malloc(), calloc(), free() and realloc() - GeeksforGeeksSorting Algorithms - GeeksforGeeksgrep command in Unix/Linux - GeeksforGeeksLinux Commands Cheat Sheet: Beginner to Advanced 2025One Hot Encoding in Machine Learning - GeeksforGeeksC++ Programming Language - GeeksforGeeksDefaultdict in Python - GeeksforGeeks*args and **kwargs in Python - GeeksforGeeksArrays in Java - GeeksforGeeksPython Lists - GeeksforGeeksDeque in Python - GeeksforGeeksSed Command in Linux/Unix With Examples - GeeksforGeeksTop 100 SQL Interview Questions and Answers (2025)C Programming Language Tutorial - GeeksforGeeksTypes of Network Topology - GeeksforGeeksTop 50+ Python Interview Questions and Answers (2025)Dynamic Programming or DP - GeeksforGeeksDecorators in Python - GeeksforGeeksMaximum Subarray Sum - Kadane's Algorithm - GeeksforGeeksSQL | WITH Clause - GeeksforGeeksStack in Python - GeeksforGeeksVector in C' metadata={'source': 'https://www.geeksforgeeks.org/top-50-software-engineering-interview-questions/', 'title': 'Page not found | GeeksforGeeks', 'language': 'en-US'}\n",
            "page_content='GeeksSQL | WITH Clause - GeeksforGeeksStack in Python - GeeksforGeeksVector in C++ STL - GeeksforGeeks\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Problem of the day\n",
            "Know more >>\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Job-A-Thon\n",
            "Know more >>\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Weekly Coding Contest\n",
            "Know more >>\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Python Tutorial\n",
            "Know more >>\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Corporate & Communications Address:\n",
            "\r\n",
            "                      A-143, 7th Floor, Sovereign Corporate Tower, Sector- 136, Noida, Uttar Pradesh (201305)                    \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Registered Address:\r\n",
            "                        K 061, Tower K, Gulshan Vivante Apartment, Sector 137, Noida, Gautam Buddh Nagar, Uttar Pradesh, 201305                      \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Advertise with us\n",
            "\n",
            "\n",
            "\n",
            "CompanyAbout UsLegalPrivacy PolicyIn MediaContact UsAdvertise with usGFG Corporate SolutionPlacement Training ProgramLanguagesPythonJavaC++PHPGoLangSQLR LanguageAndroid TutorialTutorials ArchiveDSAData StructuresAlgorithmsDSA for BeginnersBasic DSA ProblemsDSA RoadmapTop 100 DSA Interview ProblemsDSA Roadmap by Sandeep JainAll Cheat SheetsData Science & MLData Science With PythonData Science For BeginnerMachine LearningML MathsData VisualisationPandasNumPyNLPDeep LearningWeb TechnologiesHTMLCSSJavaScriptTypeScriptReactJSNextJSBootstrapWeb DesignPython TutorialPython Programming ExamplesPython ProjectsPython TkinterPython Web ScrapingOpenCV TutorialPython Interview QuestionDjangoComputer ScienceOperating SystemsComputer NetworkDatabase Management SystemSoftware EngineeringDigital Logic DesignEngineering MathsSoftware DevelopmentSoftware TestingDevOpsGitLinuxAWSDockerKubernetesAzureGCPDevOps RoadmapSystem DesignHigh Level DesignLow Level DesignUML DiagramsInterview GuideDesign PatternsOOADSystem Design BootcampInterview Questions' metadata={'source': 'https://www.geeksforgeeks.org/top-50-software-engineering-interview-questions/', 'title': 'Page not found | GeeksforGeeks', 'language': 'en-US'}\n"
          ]
        }
      ],
      "source": [
        "print(documents[0])\n",
        "print(documents[1])\n",
        "print(documents[2])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c2MEovPDGzBW"
      },
      "source": [
        "\n",
        "\n",
        "- **ChatOpenAI**: This class is used to interact with OpenAI's chat models. In this case, it's initialized with parameters like `temperature=0` and `model_name=\"gpt-3.5-turbo-0125\"`.\n",
        "- **LLMGraphTransformer**: This class is used to transform text documents into graph documents using a language model (LLM).\n",
        "- **Neo4jGraph**: This class represents a connection to a Neo4j graph database.\n",
        "\n",
        "\n",
        "The code first initializes the language model (`llm`) and the transformer (`llm_transformer`) to convert text documents (`documents`) into graph documents. Then, it initializes a `Neo4jGraph` instance (`graph`) and adds the transformed graph documents to the Neo4j database using the `add_graph_documents` method.\n",
        "\n",
        "This approach integrates natural language processing with graph database operations, enabling the creation of structured graph representations from unstructured text data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0DttkbLsyAza",
        "outputId": "1dd9e93a-8fa3-4133-9a8f-19864f67c05e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/langchain_openai/chat_models/base.py:1673: UserWarning: Cannot use method='json_schema' with model gpt-3.5-turbo-0125 since it doesn't support OpenAI's Structured Output API. You can see supported models here: https://platform.openai.com/docs/guides/structured-outputs#supported-models. To fix this warning, set `method='function_calling'. Overriding to method='function_calling'.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "llm=ChatOpenAI(temperature=0, model_name=\"gpt-3.5-turbo-0125\") # gpt-4-0125-preview occasionally has issues\n",
        "llm_transformer = LLMGraphTransformer(llm=llm)\n",
        "\n",
        "# Following needs to be used only first time to load the data. It took 3m 44s\n",
        "graph_documents = llm_transformer.convert_to_graph_documents(documents[:10])\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nW1WQB5-PYhj"
      },
      "source": [
        "**The following needs to be run for the first time when you load data into DB.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "qxodjNISPSXK"
      },
      "outputs": [],
      "source": [
        "graph.add_graph_documents(\n",
        "    graph_documents,\n",
        "    baseEntityLabel=True,\n",
        "    include_source=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zwUdvx8I5208",
        "outputId": "0080751d-937a-42ae-ac25-01c51b9b3cf6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "page_content='\n",
            "\n",
            "\n",
            "\n",
            "                  Settings\n",
            "                \n",
            "\n",
            "\n",
            "\n",
            "                  Help Requests\n",
            "                \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Profile\n",
            "\n",
            "\n",
            "Settings\n",
            "\n",
            "\n",
            "Help Requests\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "      Login to experience InterviewBit\n",
            "       \n",
            "\n",
            "\n",
            "      Sign in\n",
            "    \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "      Experience Scaler\n",
            "    \n",
            "\n",
            "      Experience Scaler\n",
            "    \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                  Profile\n",
            "                \n",
            "\n",
            "\n",
            "\n",
            "                  Settings\n",
            "                \n",
            "\n",
            "\n",
            "\n",
            "                  Help Requests\n",
            "                \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Profile\n",
            "\n",
            "\n",
            "Settings\n",
            "\n",
            "\n",
            "Help Requests\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "      Login to experience InterviewBit\n",
            "       \n",
            "\n",
            "\n",
            "      Sign in\n",
            "    \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "              Practice\n",
            "              \n",
            "                Improve your coding skills with our resources\n",
            "              \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "              Resources\n",
            "              \n",
            "                Experience learning\n",
            "              ' metadata={'source': 'https://www.interviewbit.com/software-engineering-mcq/', 'title': 'Software Engineering MCQ With Answers', 'description': \"Here's the list of 50+ Software Engineering MCQ along with Answers to brush your skills.\", 'language': 'en', 'id': '2713e25783852c33a7957ebfd64add98'}\n",
            "nodes=[Node(id='Interviewbit', type='Platform', properties={}), Node(id='Scaler', type='Platform', properties={}), Node(id='Practice', type='Activity', properties={}), Node(id='Resources', type='Activity', properties={})] relationships=[Relationship(source=Node(id='Interviewbit', type='Platform', properties={}), target=Node(id='Scaler', type='Platform', properties={}), type='PART_OF', properties={}), Relationship(source=Node(id='Scaler', type='Platform', properties={}), target=Node(id='Practice', type='Activity', properties={}), type='OFFERS', properties={}), Relationship(source=Node(id='Resources', type='Activity', properties={}), target=Node(id='Practice', type='Activity', properties={}), type='PROVIDES', properties={})] source=Document(metadata={'source': 'https://www.interviewbit.com/software-engineering-mcq/', 'title': 'Software Engineering MCQ With Answers', 'description': \"Here's the list of 50+ Software Engineering MCQ along with Answers to brush your skills.\", 'language': 'en', 'id': '2713e25783852c33a7957ebfd64add98'}, page_content='\\n\\n\\n\\n                  Settings\\n                \\n\\n\\n\\n                  Help Requests\\n                \\n\\n\\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nProfile\\n\\n\\nSettings\\n\\n\\nHelp Requests\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n      Login to experience InterviewBit\\n       \\n\\n\\n      Sign in\\n    \\n\\n\\n\\n\\n\\n\\n\\n\\n      Experience Scaler\\n    \\n\\n      Experience Scaler\\n    \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n                  Profile\\n                \\n\\n\\n\\n                  Settings\\n                \\n\\n\\n\\n                  Help Requests\\n                \\n\\n\\n\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nProfile\\n\\n\\nSettings\\n\\n\\nHelp Requests\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n      Login to experience InterviewBit\\n       \\n\\n\\n      Sign in\\n    \\n\\n\\n\\n\\n\\n\\n\\n              Practice\\n              \\n                Improve your coding skills with our resources\\n              \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n              Resources\\n              \\n                Experience learning\\n              ')\n"
          ]
        }
      ],
      "source": [
        "print (documents[5])\n",
        "print(graph_documents[5])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-76PrdloHXmK"
      },
      "source": [
        "The `showGraph` function takes an optional `Cypher `query string as input (defaulting to a predefined query), establishes a connection to `Neo4j` using credentials from environment variables, executes the query to retrieve graph data, and then visualizes it using a `GraphWidget`. The widget allows interactive exploration of the graph nodes and relationships directly within the notebook environment, making it easy to analyze and understand graph structures and connections."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 817,
          "referenced_widgets": [
            "489f6fc099494fa1a42e4894ed59e09a",
            "9dae961897a84a3fa3962a8eda16a3bc"
          ]
        },
        "id": "verAasH9yIu6",
        "outputId": "be6165af-18c4-43e4-9d54-aef8f4055e00"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "GraphWidget(layout=Layout(height='800px', width='100%'))"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "489f6fc099494fa1a42e4894ed59e09a"
            }
          },
          "metadata": {
            "application/vnd.jupyter.widget-view+json": {
              "colab": {
                "custom_widget_manager": {
                  "url": "https://ssl.gstatic.com/colaboratory-static/widgets/colab-cdn-widget-manager/2b70e893a8ba7c0f/manager.min.js"
                }
              }
            }
          }
        }
      ],
      "source": [
        "# directly show the graph resulting from the given Cypher query\n",
        "default_cypher = \"MATCH (s)-[r:!MENTIONS]->(t) RETURN s,r,t LIMIT 50\"\n",
        "\n",
        "def showGraph(cypher: str = default_cypher):\n",
        "    # create a neo4j session to run queries\n",
        "    driver = GraphDatabase.driver(\n",
        "        uri = os.environ[\"NEO4J_URI\"],\n",
        "        auth = (os.environ[\"NEO4J_USERNAME\"],\n",
        "                os.environ[\"NEO4J_PASSWORD\"]))\n",
        "    session = driver.session()\n",
        "    widget = GraphWidget(graph = session.run(cypher).graph())\n",
        "    widget.node_label_mapping = 'id'\n",
        "    #display(widget)\n",
        "    return widget\n",
        "\n",
        "showGraph()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2LSQjHkAHuTj"
      },
      "source": [
        "The `Neo4jVector.from_existing_graph()` method is used to create a vector index within a Neo4j database. It integrates embeddings from OpenAI's models, facilitating efficient search and retrieval operations based on both textual content and embedding similarities.\n",
        "\n",
        "### Key Components:\n",
        "\n",
        "- **LangChain Components**:\n",
        "  - **Neo4jVector**: This class from LangChain Community is designed to manage vector indexes within Neo4j, enabling storage and retrieval of embeddings associated with graph nodes.\n",
        "  - **OpenAIEmbeddings**: This class from LangChain OpenAI provides tools for generating embeddings using OpenAI's models.\n",
        "\n",
        "- **Initialization Parameters**:\n",
        "  - **OpenAIEmbeddings()**: Initializes the use of OpenAI's models to generate embeddings.\n",
        "  - **search_type=\"hybrid\"**: Specifies a hybrid search approach, leveraging both textual content and embedding similarities for efficient querying.\n",
        "  - **node_label=\"Document\"**: Specifies that nodes labeled \"Document\" in the Neo4j graph will store document-related information.\n",
        "  - **text_node_properties=[\"text\"]**: Defines the property name(s) within \"Document\" nodes where textual content is stored.\n",
        "  - **embedding_node_property=\"embedding\"**: Specifies the property name where embeddings are stored within the \"Document\" nodes.\n",
        "\n",
        "### Usage Scenario:\n",
        "\n",
        "This setup is useful in scenarios where you want to store and query documents based on both their textual content and their embeddings. For example, you can store documents in Neo4j, extract their embeddings using OpenAI's models, and then use this vector index to efficiently search for documents based on their semantic similarity to a given query or to other documents in the database.\n",
        "\n",
        "This approach leverages the capabilities of Neo4j for graph-based storage and retrieval, coupled with advanced embedding techniques from OpenAI, providing a powerful toolset for managing and analyzing textual data within a graph database environment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "J23HXjaEzdu8"
      },
      "outputs": [],
      "source": [
        "vector_index = Neo4jVector.from_existing_graph(\n",
        "    OpenAIEmbeddings(),\n",
        "    search_type=\"hybrid\",\n",
        "    node_label=\"Document\",\n",
        "    text_node_properties=[\"text\"],\n",
        "    embedding_node_property=\"embedding\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U__qaE9sHtW8"
      },
      "source": [
        "\n",
        "\n",
        "### Retriever Setup:\n",
        "\n",
        "The code snippet performs the following actions:\n",
        "\n",
        "1. **Create Fulltext Index**:\n",
        "   - The `graph.query()` statement creates a fulltext index named `entity` if it does not already exist. This index is applied to nodes labeled `__Entity__` and indexes the `id` property of these nodes for efficient querying.\n",
        "\n",
        "2. **Entity Data Model**:\n",
        "   - The `Entities` class, derived from `BaseModel`, defines a structured representation for identifying information about entities extracted from text.\n",
        "   - **Names**: A list of strings representing entities such as courses, professors, requirements, or project entities found in the text.\n",
        "\n",
        "3. **Chat Prompt Template**:\n",
        "   - The `ChatPromptTemplate.from_messages()` method initializes a prompt template for interacting with users.\n",
        "   - The prompt consists of a system message informing the user about the extraction task and a human message specifying the format for input to extract information.\n",
        "\n",
        "4. **Entity Chain**:\n",
        "   - The `prompt | llm.with_structured_output(Entities)` constructs an entity extraction pipeline using LangChain:\n",
        "     - **Prompt**: Provides instructions to the user on how to input questions or text for entity extraction.\n",
        "     - **LLM (Language Model)**: Processes the input using OpenAI's language model to extract structured entities as defined by the `Entities` class.\n",
        "\n",
        "### Usage:\n",
        "\n",
        "This setup is designed to facilitate the extraction of entities from text input in a structured and systematic manner. The fulltext index ensures that entity nodes in the Neo4j graph are efficiently indexed, allowing for quick retrieval of relevant entities based on their `id` property. The `Entities` data model and the prompt template guide the interaction with users, ensuring that the extraction process is clear and consistent.\n",
        "\n",
        "This approach leverages natural language processing and graph database capabilities to manage and analyze textual data effectively, supporting tasks such as information extraction, entity linking, and knowledge base population within a broader application or system."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4DLAEMgHz2nF",
        "outputId": "6ef60e87-3942-4ddf-a6f9-5ef817dc2ad6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/langchain_openai/chat_models/base.py:1660: UserWarning: Received a Pydantic BaseModel V1 schema. This is not supported by method=\"json_schema\". Please use method=\"function_calling\" or specify schema via JSON Schema or Pydantic V2 BaseModel. Overriding to method=\"function_calling\".\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/langchain_openai/chat_models/base.py:1673: UserWarning: Cannot use method='json_schema' with model gpt-3.5-turbo-0125 since it doesn't support OpenAI's Structured Output API. You can see supported models here: https://platform.openai.com/docs/guides/structured-outputs#supported-models. To fix this warning, set `method='function_calling'. Overriding to method='function_calling'.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# Retriever\n",
        "\n",
        "graph.query(\n",
        "    \"CREATE FULLTEXT INDEX entity IF NOT EXISTS FOR (e:__Entity__) ON EACH [e.id]\")\n",
        "\n",
        "# Extract entities from text\n",
        "class Entities(BaseModel):\n",
        "    \"\"\"Identifying information about entities.\"\"\"\n",
        "\n",
        "    names: List[str] = Field(\n",
        "        ...,\n",
        "        description=\"All the courses, requirements, or business entities that \"\n",
        "        \"appear in the text\",\n",
        "    )\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\n",
        "            \"system\",\n",
        "            \"You are extracting course, professors, requirements, project entities from the text.\",\n",
        "        ),\n",
        "        (\n",
        "            \"human\",\n",
        "            \"Use the given format to extract information from the following \"\n",
        "            \"input: {question}\",\n",
        "        ),\n",
        "    ]\n",
        ")\n",
        "\n",
        "entity_chain = prompt | llm.with_structured_output(Entities)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_JKJNR3YWU-p"
      },
      "source": [
        "### Description\n",
        "\n",
        "This script is used to retrieve related information from a Neo4j graph database based on user input.\n",
        "\n",
        "#### Functions:\n",
        "\n",
        "- **`generate_full_text_query(input: str)`**  \n",
        "  Converts a given input string into a fuzzy full-text search query.  \n",
        "  - Splits the input into individual words.\n",
        "  - Appends a similarity threshold (`~2`) to each word to allow minor misspellings.\n",
        "  - Combines the words using the `AND` operator for more accurate matching.\n",
        "\n",
        "- **`structured_retriever(question: str)`**  \n",
        "  Extracts entities from a natural language question and fetches related nodes from the graph.  \n",
        "  - Uses `entity_chain` to extract key entity names from the question.\n",
        "  - For each entity, performs a full-text search using the generated query.\n",
        "  - Retrieves up to 50 paths showing relationships to and from each matching node.\n",
        "  - Returns the results as a formatted string."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "V1jRiI6G0J6P"
      },
      "outputs": [],
      "source": [
        "def generate_full_text_query(input: str) -> str:\n",
        "    \"\"\"\n",
        "    Generate a full-text search query for a given input string.\n",
        "\n",
        "    This function constructs a query string suitable for a full-text search.\n",
        "    It processes the input string by splitting it into words and appending a\n",
        "    similarity threshold (~2 changed characters) to each word, then combines\n",
        "    them using the AND operator. Useful for mapping entities from user questions\n",
        "    to database values, and allows for some misspelings.\n",
        "    \"\"\"\n",
        "    full_text_query = \"\"\n",
        "    words = [el for el in remove_lucene_chars(input).split() if el]\n",
        "    for word in words[:-1]:\n",
        "        full_text_query += f\" {word}~2 AND\"\n",
        "    full_text_query += f\" {words[-1]}~2\"\n",
        "    return full_text_query.strip()\n",
        "\n",
        "# Fulltext index query\n",
        "def structured_retriever(question: str) -> str:\n",
        "    \"\"\"\n",
        "    Collects the neighborhood of entities mentioned\n",
        "    in the question\n",
        "    \"\"\"\n",
        "    result = \"\"\n",
        "    entities = entity_chain.invoke({\"question\": question})\n",
        "    for entity in entities.names:\n",
        "        response = graph.query(\n",
        "            \"\"\"CALL db.index.fulltext.queryNodes('entity', $query, {limit:2})\n",
        "            YIELD node,score\n",
        "            CALL {\n",
        "              WITH node\n",
        "              MATCH (node)-[r:!MENTIONS]->(neighbor)\n",
        "              RETURN node.id + ' - ' + type(r) + ' -> ' + neighbor.id AS output\n",
        "              UNION ALL\n",
        "              WITH node\n",
        "              MATCH (node)<-[r:!MENTIONS]-(neighbor)\n",
        "              RETURN neighbor.id + ' - ' + type(r) + ' -> ' +  node.id AS output\n",
        "            }\n",
        "            RETURN output LIMIT 50\n",
        "            \"\"\",\n",
        "            {\"query\": generate_full_text_query(entity)},\n",
        "        )\n",
        "        result += \"\\n\".join([el['output'] for el in response])\n",
        "    return result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aDRKabxJWU-q"
      },
      "source": [
        "- **`retriever(question: str)`**  \n",
        "  Combines results from both structured and unstructured data sources to answer a user question.  \n",
        "  - Logs the original search query.\n",
        "  - Uses `structured_retriever` to fetch entity-related information from a Neo4j graph (structured data).\n",
        "  - Performs a similarity search over a vector index to retrieve relevant documents (unstructured data).\n",
        "  - Formats and returns both data types in a combined response.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "C1ftDuLy0P8X"
      },
      "outputs": [],
      "source": [
        "def retriever(question: str):\n",
        "    print(f\"🔍 Search query: {question}\")\n",
        "\n",
        "    # Run structured retrieval\n",
        "    structured_data = structured_retriever(question)\n",
        "\n",
        "    # Run unstructured vector search\n",
        "    unstructured_data = [\n",
        "        el.page_content for el in vector_index.similarity_search(question)\n",
        "    ]\n",
        "\n",
        "    # Safely join unstructured results\n",
        "    unstructured_output = \"\\n\\n# Document:\\n\".join(unstructured_data)\n",
        "\n",
        "    # Final combined context\n",
        "    final_data = f\"\"\"📊 Structured data from Neo4j:\n",
        "{structured_data}\n",
        "\n",
        "📚 Unstructured data from vector index:\n",
        "{unstructured_output}\n",
        "    \"\"\"\n",
        "\n",
        "    return final_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b_-vBRUQWU-r"
      },
      "source": [
        "### Condensing Chat History for Standalone Question Generation\n",
        "\n",
        "This code helps rephrase a follow-up question into a standalone question by considering the previous chat history.\n",
        "\n",
        "#### Components:\n",
        "\n",
        "- **`_template` and `CONDENSE_QUESTION_PROMPT`**  \n",
        "  Defines a prompt template used to generate a standalone question from a follow-up query and previous chat context.\n",
        "\n",
        "- **`_format_chat_history(chat_history: List[Tuple[str, str]]) -> List`**  \n",
        "  Converts a list of chat history (pairs of human and AI messages) into a format compatible with LLMs, using `HumanMessage` and `AIMessage` objects.\n",
        "\n",
        "- **`_search_query`**  \n",
        "  A conditional chain (`RunnableBranch`) that:\n",
        "  - If chat history exists:\n",
        "    - Formats the history.\n",
        "    - Fills the prompt with the history and the follow-up question.\n",
        "    - Sends it to an LLM (e.g., OpenAI) to generate a standalone question.\n",
        "  - If no chat history exists:\n",
        "    - Returns the original question as-is.\n",
        "\n",
        "This setup is typically used to improve retrieval or question answering pipelines by ensuring queries are self-contained.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "azltkyJN0U_I"
      },
      "outputs": [],
      "source": [
        "# Condense a chat history and follow-up question into a standalone question\n",
        "_template = \"\"\"Given the following conversation and a follow up question, rephrase the follow up question to be a standalone question,\n",
        "in its original language.\n",
        "Chat History:\n",
        "{chat_history}\n",
        "Follow Up Input: {question}\n",
        "Standalone question:\"\"\"  # noqa: E501\n",
        "CONDENSE_QUESTION_PROMPT = PromptTemplate.from_template(_template)\n",
        "\n",
        "def _format_chat_history(chat_history: List[Tuple[str, str]]) -> List:\n",
        "    buffer = []\n",
        "    for human, ai in chat_history:\n",
        "        buffer.append(HumanMessage(content=human))\n",
        "        buffer.append(AIMessage(content=ai))\n",
        "    return buffer\n",
        "\n",
        "_search_query = RunnableBranch(\n",
        "    # If input includes chat_history, we condense it with the follow-up question\n",
        "    (\n",
        "        RunnableLambda(lambda x: bool(x.get(\"chat_history\"))).with_config(\n",
        "            run_name=\"HasChatHistoryCheck\"\n",
        "        ),  # Condense follow-up question and chat into a standalone_question\n",
        "        RunnablePassthrough.assign(\n",
        "            chat_history=lambda x: _format_chat_history(x[\"chat_history\"])\n",
        "        )\n",
        "        | CONDENSE_QUESTION_PROMPT\n",
        "        | ChatOpenAI(temperature=0)\n",
        "        | StrOutputParser(),\n",
        "    ),\n",
        "    # Else, we have no chat history, so just pass through the question\n",
        "    RunnableLambda(lambda x : x[\"question\"]),\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tpA9dhbRWU-6"
      },
      "source": [
        "### Answering a Question Using Context-Aware Retrieval\n",
        "\n",
        "This code defines a chain that answers a user question based only on retrieved context from structured and unstructured sources.\n",
        "\n",
        "#### Components:\n",
        "\n",
        "- **`template` and `prompt`**  \n",
        "  A prompt template that:\n",
        "  - Inserts the relevant context and the user's question.\n",
        "  - Instructs the model to respond in natural, concise language.\n",
        "\n",
        "- **`chain`**  \n",
        "  A composed pipeline that:\n",
        "  - Runs two parallel steps:\n",
        "    - **`_search_query | retriever`**: Uses the `_search_query` logic to condense the question (if chat history exists), and then fetches relevant context via the `retriever` function.\n",
        "    - **`RunnablePassthrough()`**: Passes the original question directly.\n",
        "  - Fills the `prompt` with the retrieved context and question.\n",
        "  - Sends the filled prompt to the language model (`llm`) to generate a response.\n",
        "  - Parses and returns the final answer as a plain string.\n",
        "\n",
        "This setup ensures that the model's response is grounded in actual retrieved knowledge, improving relevance and accuracy.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "Bru0C7ox0aJY"
      },
      "outputs": [],
      "source": [
        "# Answer the question based only on the following context\n",
        "template = \"\"\"Answer the query:\n",
        "{context}\n",
        "\n",
        "Question: {question}\n",
        "Use natural language and be concise.\n",
        "Answer:\"\"\"\n",
        "prompt = ChatPromptTemplate.from_template(template)\n",
        "\n",
        "chain = (\n",
        "    RunnableParallel(\n",
        "        {\n",
        "            \"context\": _search_query | retriever,\n",
        "            \"question\": RunnablePassthrough(),\n",
        "        }\n",
        "    )\n",
        "    | prompt\n",
        "    | llm\n",
        "    | StrOutputParser()\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "87XK7HSgWU-8"
      },
      "source": [
        "### `chain.invoke({\"question\": \"...\"})` — What It Does\n",
        "\n",
        "This command executes a full pipeline that answers a user’s question by retrieving relevant data from both structured and unstructured sources."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oBOP7MYrV3Af"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        },
        "id": "Xv4LdswWPvZe",
        "outputId": "97deee07-3261-44b9-cbd9-19ae8e311b4e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Search query: What are common interview questions for AI-related roles?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:neo4j.notifications:Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.FeatureDeprecationWarning} {category: DEPRECATION} {title: This feature is deprecated and will be removed in future versions.} {description: CALL subquery without a variable scope clause is now deprecated. Use CALL (node, node) { ... }} {position: line: 3, column: 13, offset: 104} for query: \"CALL db.index.fulltext.queryNodes('entity', $query, {limit:2})\\n            YIELD node,score\\n            CALL {\\n              WITH node\\n              MATCH (node)-[r:!MENTIONS]->(neighbor)\\n              RETURN node.id + ' - ' + type(r) + ' -> ' + neighbor.id AS output\\n              UNION ALL\\n              WITH node\\n              MATCH (node)<-[r:!MENTIONS]-(neighbor)\\n              RETURN neighbor.id + ' - ' + type(r) + ' -> ' +  node.id AS output\\n            }\\n            RETURN output LIMIT 50\\n            \"\n",
            "WARNING:neo4j.notifications:Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.FeatureDeprecationWarning} {category: DEPRECATION} {title: This feature is deprecated and will be removed in future versions.} {description: CALL subquery without a variable scope clause is now deprecated. Use CALL (node, node) { ... }} {position: line: 3, column: 13, offset: 104} for query: \"CALL db.index.fulltext.queryNodes('entity', $query, {limit:2})\\n            YIELD node,score\\n            CALL {\\n              WITH node\\n              MATCH (node)-[r:!MENTIONS]->(neighbor)\\n              RETURN node.id + ' - ' + type(r) + ' -> ' + neighbor.id AS output\\n              UNION ALL\\n              WITH node\\n              MATCH (node)<-[r:!MENTIONS]-(neighbor)\\n              RETURN neighbor.id + ' - ' + type(r) + ' -> ' +  node.id AS output\\n            }\\n            RETURN output LIMIT 50\\n            \"\n",
            "WARNING:neo4j.notifications:Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.FeatureDeprecationWarning} {category: DEPRECATION} {title: This feature is deprecated and will be removed in future versions.} {description: CALL subquery without a variable scope clause is now deprecated. Use CALL () { ... }} {position: line: 1, column: 1, offset: 0} for query: \"CALL { CALL db.index.vector.queryNodes($index, $k, $embedding) YIELD node, score WITH collect({node:node, score:score}) AS nodes, max(score) AS max UNWIND nodes AS n RETURN n.node AS node, (n.score / max) AS score UNION CALL db.index.fulltext.queryNodes($keyword_index, $query, {limit: $k}) YIELD node, score WITH collect({node:node, score:score}) AS nodes, max(score) AS max UNWIND nodes AS n RETURN n.node AS node, (n.score / max) AS score } WITH node, max(score) AS score ORDER BY score DESC LIMIT $k RETURN reduce(str='', k IN ['text'] | str + '\\\\n' + k + ': ' + coalesce(node[k], '')) AS text, node {.*, `embedding`: Null, id: Null, `text`: Null} AS metadata, score\"\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Common interview questions for AI-related roles may include:\\n1. Can you explain the difference between supervised and unsupervised learning?\\n2. How do you handle overfitting in machine learning models?\\n3. What is the difference between classification and regression?\\n4. Can you explain the concept of neural networks?\\n5. How do you evaluate the performance of a machine learning model?\\n6. Have you worked with natural language processing (NLP) algorithms?\\n7. How do you approach feature selection in a machine learning project?\\n8. Can you explain the concept of reinforcement learning?\\n9. Have you implemented any deep learning models?\\n10. How do you stay updated with the latest trends in artificial intelligence?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "chain.invoke({\"question\": \"What are common interview questions for AI-related roles?\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "id": "L5C9R3Pp0lrw",
        "outputId": "adee065d-a370-4a33-b950-3d2168b96c37"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Search query: Is Machine Learning a required course in the MSACS program?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:neo4j.notifications:Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.FeatureDeprecationWarning} {category: DEPRECATION} {title: This feature is deprecated and will be removed in future versions.} {description: CALL subquery without a variable scope clause is now deprecated. Use CALL (node, node) { ... }} {position: line: 3, column: 13, offset: 104} for query: \"CALL db.index.fulltext.queryNodes('entity', $query, {limit:2})\\n            YIELD node,score\\n            CALL {\\n              WITH node\\n              MATCH (node)-[r:!MENTIONS]->(neighbor)\\n              RETURN node.id + ' - ' + type(r) + ' -> ' + neighbor.id AS output\\n              UNION ALL\\n              WITH node\\n              MATCH (node)<-[r:!MENTIONS]-(neighbor)\\n              RETURN neighbor.id + ' - ' + type(r) + ' -> ' +  node.id AS output\\n            }\\n            RETURN output LIMIT 50\\n            \"\n",
            "WARNING:neo4j.notifications:Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.FeatureDeprecationWarning} {category: DEPRECATION} {title: This feature is deprecated and will be removed in future versions.} {description: CALL subquery without a variable scope clause is now deprecated. Use CALL (node, node) { ... }} {position: line: 3, column: 13, offset: 104} for query: \"CALL db.index.fulltext.queryNodes('entity', $query, {limit:2})\\n            YIELD node,score\\n            CALL {\\n              WITH node\\n              MATCH (node)-[r:!MENTIONS]->(neighbor)\\n              RETURN node.id + ' - ' + type(r) + ' -> ' + neighbor.id AS output\\n              UNION ALL\\n              WITH node\\n              MATCH (node)<-[r:!MENTIONS]-(neighbor)\\n              RETURN neighbor.id + ' - ' + type(r) + ' -> ' +  node.id AS output\\n            }\\n            RETURN output LIMIT 50\\n            \"\n",
            "WARNING:neo4j.notifications:Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.FeatureDeprecationWarning} {category: DEPRECATION} {title: This feature is deprecated and will be removed in future versions.} {description: CALL subquery without a variable scope clause is now deprecated. Use CALL () { ... }} {position: line: 1, column: 1, offset: 0} for query: \"CALL { CALL db.index.vector.queryNodes($index, $k, $embedding) YIELD node, score WITH collect({node:node, score:score}) AS nodes, max(score) AS max UNWIND nodes AS n RETURN n.node AS node, (n.score / max) AS score UNION CALL db.index.fulltext.queryNodes($keyword_index, $query, {limit: $k}) YIELD node, score WITH collect({node:node, score:score}) AS nodes, max(score) AS max UNWIND nodes AS n RETURN n.node AS node, (n.score / max) AS score } WITH node, max(score) AS score ORDER BY score DESC LIMIT $k RETURN reduce(str='', k IN ['text'] | str + '\\\\n' + k + ': ' + coalesce(node[k], '')) AS text, node {.*, `embedding`: Null, id: Null, `text`: Null} AS metadata, score\"\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'No, Machine Learning is not a required course in the MSACS program.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "#True Positive\n",
        "chain.invoke({\"question\": \"Is Machine Learning a required course in the MSACS program?\"})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "en1XQ9DlWU-_"
      },
      "source": [
        "### Disabling Warnings and Setting Logging Levels for Neo4j\n",
        "\n",
        "This code snippet is used to **suppress warnings** and **set logging levels** for specific parts of the code, especially in the context of working with the Neo4j database.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "QAd4_yQDRQMv"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "import logging\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "logging.getLogger(\"neo4j.notifications\").setLevel(logging.ERROR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "duilHxHs1Ac9",
        "outputId": "1108cc93-0392-471a-a8c1-22f8d59cd28e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Search query: Is knowledge of Python unnecessary for AI roles?\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Knowledge of Python is essential for AI roles as it is widely used in AI development for its simplicity, versatility, and extensive libraries.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "#True Negative\n",
        "chain.invoke({\"question\": \"Is knowledge of Python unnecessary for AI roles?\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "S7CARN8C1IRB",
        "outputId": "434908ce-a0e2-4cdc-a97d-bd6502a5ea27"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Search query: Is Python not essential for AI interview preparation?\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Python is essential for AI interview preparation.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "# False Negative\n",
        "chain.invoke({\"question\": \"Is Python not essential for AI interview preparation?\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "FR1gMLPx1S0M",
        "outputId": "0fe479c0-1ab9-4b3d-d4a6-404fecc8f2fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Search query: Are MSACS students eligible to work on AI projects during the program?\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Yes, MSACS students are eligible to work on AI projects during the program.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 45
        }
      ],
      "source": [
        "# False Positives\n",
        "chain.invoke({\"question\": \"Are MSACS students eligible to work on AI projects during the program?\"})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JHVxM45pR1p5"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "EIkFhW5cWU_G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa075c52-4440-4b6d-a3bd-05abdca63577"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting main.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile main.py\n",
        "from langchain_core.runnables import (\n",
        "    RunnableBranch,\n",
        "    RunnableLambda,\n",
        "    RunnableParallel,\n",
        "    RunnablePassthrough,\n",
        ")\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.prompts.prompt import PromptTemplate\n",
        "from langchain_core.pydantic_v1 import BaseModel, Field\n",
        "from typing import Tuple, List, Optional\n",
        "from langchain_core.messages import AIMessage, HumanMessage\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "import os\n",
        "from langchain_community.graphs import Neo4jGraph\n",
        "from langchain.text_splitter import TokenTextSplitter\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_experimental.graph_transformers import LLMGraphTransformer\n",
        "from neo4j import GraphDatabase\n",
        "from langchain_community.vectorstores import Neo4jVector\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "from langchain_community.vectorstores.neo4j_vector import remove_lucene_chars\n",
        "from langchain_core.runnables import ConfigurableField, RunnableParallel, RunnablePassthrough\n",
        "\n",
        "\n",
        "try:\n",
        "  import google.colab\n",
        "  from google.colab import output\n",
        "  output.enable_custom_widget_manager()\n",
        "except:\n",
        "  pass\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"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\"#replace your OPEN_API key\n",
        "os.environ[\"NEO4J_URI\"] = \"neo4j+s://4e016907.databases.neo4j.io\"#NEO4J URL\n",
        "os.environ[\"NEO4J_USERNAME\"] = \"neo4j\" #NEO4J USERNAME\n",
        "os.environ[\"NEO4J_PASSWORD\"] = \"xdrgsXAbPcI3DY4Fkl7NKt51WaguG8k6ihDksSNA5ZM\"#NEO4J PASSWORD\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "_search_query = RunnableLambda(lambda x : x[\"question\"])\n",
        "\n",
        "\n",
        "graph = Neo4jGraph()\n",
        "\n",
        "llm=ChatOpenAI(temperature=0, model_name=\"gpt-3.5-turbo-0125\") # gpt-4-0125-preview occasionally has issues\n",
        "llm_transformer = LLMGraphTransformer(llm=llm)\n",
        "\n",
        "vector_index = Neo4jVector.from_existing_graph(\n",
        "    OpenAIEmbeddings(),\n",
        "    search_type=\"hybrid\",\n",
        "    node_label=\"Document\",\n",
        "    text_node_properties=[\"text\"],\n",
        "    embedding_node_property=\"embedding\"\n",
        ")\n",
        "\n",
        "\n",
        "graph.query(\n",
        "    \"CREATE FULLTEXT INDEX entity IF NOT EXISTS FOR (e:__Entity__) ON EACH [e.id]\")\n",
        "\n",
        "# Extract entities from text\n",
        "class Entities(BaseModel):\n",
        "    \"\"\"Identifying information about entities.\"\"\"\n",
        "\n",
        "    names: List[str] = Field(\n",
        "        ...,\n",
        "        description=\"All the courses, requirements, or business entities that \"\n",
        "        \"appear in the text\",\n",
        "    )\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\n",
        "            \"system\",\n",
        "            \"You are extracting course, professors, requirements, project entities from the text.\",\n",
        "        ),\n",
        "        (\n",
        "            \"human\",\n",
        "            \"Use the given format to extract information from the following \"\n",
        "            \"input: {question}\",\n",
        "        ),\n",
        "    ]\n",
        ")\n",
        "\n",
        "entity_chain = prompt | llm.with_structured_output(Entities)\n",
        "\n",
        "def generate_full_text_query(input: str) -> str:\n",
        "    \"\"\"\n",
        "    Generate a full-text search query for a given input string.\n",
        "\n",
        "    This function constructs a query string suitable for a full-text search.\n",
        "    It processes the input string by splitting it into words and appending a\n",
        "    similarity threshold (~2 changed characters) to each word, then combines\n",
        "    them using the AND operator. Useful for mapping entities from user questions\n",
        "    to database values, and allows for some misspelings.\n",
        "    \"\"\"\n",
        "    full_text_query = \"\"\n",
        "    words = [el for el in remove_lucene_chars(input).split() if el]\n",
        "    for word in words[:-1]:\n",
        "        full_text_query += f\" {word}~2 AND\"\n",
        "    full_text_query += f\" {words[-1]}~2\"\n",
        "    return full_text_query.strip()\n",
        "\n",
        "# Fulltext index query\n",
        "def structured_retriever(question: str) -> str:\n",
        "    \"\"\"\n",
        "    Collects the neighborhood of entities mentioned\n",
        "    in the question\n",
        "    \"\"\"\n",
        "    result = \"\"\n",
        "    entities = entity_chain.invoke({\"question\": question})\n",
        "    for entity in entities.names:\n",
        "        response = graph.query(\n",
        "            \"\"\"CALL db.index.fulltext.queryNodes('entity', $query, {limit:2})\n",
        "            YIELD node,score\n",
        "            CALL {\n",
        "              WITH node\n",
        "              MATCH (node)-[r:!MENTIONS]->(neighbor)\n",
        "              RETURN node.id + ' - ' + type(r) + ' -> ' + neighbor.id AS output\n",
        "              UNION ALL\n",
        "              WITH node\n",
        "              MATCH (node)<-[r:!MENTIONS]-(neighbor)\n",
        "              RETURN neighbor.id + ' - ' + type(r) + ' -> ' +  node.id AS output\n",
        "            }\n",
        "            RETURN output LIMIT 50\n",
        "            \"\"\",\n",
        "            {\"query\": generate_full_text_query(entity)},\n",
        "        )\n",
        "        result += \"\\n\".join([el['output'] for el in response])\n",
        "    return result\n",
        "\n",
        "def retriever(question: str):\n",
        "    print(f\"Search query: {question}\")\n",
        "    structured_data = structured_retriever(question)\n",
        "    unstructured_data = [el.page_content for el in vector_index.similarity_search(question)]\n",
        "    final_data = f\"\"\" Structured data: {structured_data} Unstructured data: {\"#Document \". join(unstructured_data)}  \"\"\"\n",
        "    return final_data\n",
        "\n",
        "\n",
        "def answerquery(question: str):\n",
        "  template = \"\"\"Answer the question based only on the following context:\n",
        "  {context}\n",
        "\n",
        "  Question: {question}\n",
        "  Use natural language and be concise.\n",
        "  Answer:\"\"\"\n",
        "  prompt = ChatPromptTemplate.from_template(template)\n",
        "\n",
        "  chain = (\n",
        "      RunnableParallel(\n",
        "          {\n",
        "              \"context\": _search_query | retriever,\n",
        "              \"question\": RunnablePassthrough(),\n",
        "          }\n",
        "      )\n",
        "      | prompt\n",
        "      | llm\n",
        "      | StrOutputParser()\n",
        "  )\n",
        "\n",
        "  return chain.invoke(({\"question\": question}))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "UzFfyTKBZfoa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "62923419-e441-42e0-d82b-567b54491af3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "from main import answerquery\n",
        "\n",
        "st.title(\"Interview QA Chatbot\")\n",
        "\n",
        "# Initialize chat history\n",
        "if \"messages\" not in st.session_state:\n",
        "    st.session_state.messages = []\n",
        "\n",
        "# Display chat messages from history on app rerun\n",
        "for message in st.session_state.messages:\n",
        "    with st.chat_message(message[\"role\"]):\n",
        "        st.markdown(message[\"content\"])\n",
        "\n",
        "# React to user input\n",
        "if prompt := st.text_input(\"What is up?\"):\n",
        "    # Display user message in chat message container\n",
        "    st.chat_message(\"user\").markdown(prompt)\n",
        "    # Add user message to chat history\n",
        "    st.session_state.messages.append({\"role\": \"user\", \"content\": prompt})\n",
        "\n",
        "    response = answerquery(prompt)\n",
        "    # Display assistant response in chat message container\n",
        "    with st.chat_message(\"assistant\"):\n",
        "        st.markdown(response)\n",
        "    # Add assistant response to chat history\n",
        "    st.session_state.messages.append({\"role\": \"assistant\", \"content\": response})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NFaxmm4cZyu9",
        "outputId": "9652989c-ae6b-4ebb-feb7-d28346ffbdae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
            "\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://35.204.52.223:8501\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Stopping...\u001b[0m\n",
            "^C\n"
          ]
        }
      ],
      "source": [
        "!streamlit run app.py"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.6"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "489f6fc099494fa1a42e4894ed59e09a": {
          "model_module": "yfiles-jupyter-graphs",
          "model_name": "GraphModel",
          "model_module_version": "^1.10.5",
          "state": {
            "_context_pane_mapping": [
              {
                "id": "Neighborhood",
                "title": "Neighborhood"
              },
              {
                "id": "Data",
                "title": "Data"
              },
              {
                "id": "Search",
                "title": "Search"
              },
              {
                "id": "About",
                "title": "About"
              }
            ],
            "_data_importer": "neo4j",
            "_directed": true,
            "_dom_classes": [],
            "_edges": [
              {
                "id": 1152922604118474800,
                "start": 70,
                "end": 71,
                "properties": {
                  "label": "RELATED_TO"
                },
                "color": "#673AB7",
                "thickness_factor": 1,
                "directed": true,
                "styles": {},
                "label": "RELATED_TO"
              },
              {
                "id": 1155174403932160000,
                "start": 70,
                "end": 72,
                "properties": {
                  "label": "RELATED_TO"
                },
                "color": "#673AB7",
                "thickness_factor": 1,
                "directed": true,
                "styles": {},
                "label": "RELATED_TO"
              },
              {
                "id": 1152948992397541400,
                "start": 70,
                "end": 210,
                "properties": {
                  "label": "EXPLAINS"
                },
                "color": "#CDDC39",
                "thickness_factor": 1,
                "directed": true,
                "styles": {},
                "label": "EXPLAINS"
              },
              {
                "id": 1152922604118474800,
                "start": 71,
                "end": 72,
                "properties": {
                  "label": "RELATED_TO"
                },
                "color": "#673AB7",
                "thickness_factor": 1,
                "directed": true,
                "styles": {},
                "label": "RELATED_TO"
              },
              {
                "id": 1155174403932160000,
                "start": 71,
                "end": 74,
                "properties": {
                  "label": "RELATED_TO"
                },
                "color": "#673AB7",
                "thickness_factor": 1,
                "directed": true,
                "styles": {},
                "label": "RELATED_TO"
              },
              {
                "id": 1157426203745845200,
                "start": 71,
                "end": 75,
                "properties": {
                  "label": "RELATED_TO"
                },
                "color": "#673AB7",
                "thickness_factor": 1,
                "directed": true,
                "styles": {},
                "label": "RELATED_TO"
              },
              {
                "id": 1152950091909169200,
                "start": 71,
                "end": 72,
                "properties": {
                  "label": "USES"
                },
                "color": "#9E9E9E",
                "thickness_factor": 1,
                "directed": true,
                "styles": {},
                "label": "USES"
              },
              {
                "id": 1152948992397541400,
                "start": 73,
                "end": 211,
                "properties": {
                  "label": "EXPLAINS"
                },
                "color": "#CDDC39",
                "thickness_factor": 1,
                "directed": true,
                "styles": {},
                "label": "EXPLAINS"
              },
              {
                "id": 1152952290932424700,
                "start": 128,
                "end": 109,
                "properties": {
                  "label": "OFFERS"
                },
                "color": "#9C27B0",
                "thickness_factor": 1,
                "directed": true,
                "styles": {},
                "label": "OFFERS"
              },
              {
                "id": 1152923703630102800,
                "start": 129,
                "end": 134,
                "properties": {
                  "label": "PROVIDES"
                },
                "color": "#2196F3",
                "thickness_factor": 1,
                "directed": true,
                "styles": {},
                "label": "PROVIDES"
              },
              {
                "id": 1155175503443788000,
                "start": 133,
                "end": 109,
                "properties": {
                  "label": "PROVIDES"
                },
                "color": "#2196F3",
                "thickness_factor": 1,
                "directed": true,
                "styles": {},
                "label": "PROVIDES"
              },
              {
                "id": 1152923703630102800,
                "start": 133,
                "end": 129,
                "properties": {
                  "label": "PROVIDES"
                },
                "color": "#2196F3",
                "thickness_factor": 1,
                "directed": true,
                "styles": {},
                "label": "PROVIDES"
              },
              {
                "id": 1152951191420797200,
                "start": 133,
                "end": 128,
                "properties": {
                  "label": "PART_OF"
                },
                "color": "#4CAF50",
                "thickness_factor": 1,
                "directed": true,
                "styles": {},
                "label": "PART_OF"
              },
              {
                "id": 1155175503443788000,
                "start": 134,
                "end": 109,
                "properties": {
                  "label": "PROVIDES"
                },
                "color": "#2196F3",
                "thickness_factor": 1,
                "directed": true,
                "styles": {},
                "label": "PROVIDES"
              },
              {
                "id": 1152922604118475000,
                "start": 136,
                "end": 110,
                "properties": {
                  "label": "RELATED_TO"
                },
                "color": "#673AB7",
                "thickness_factor": 1,
                "directed": true,
                "styles": {},
                "label": "RELATED_TO"
              },
              {
                "id": 1155174403932160300,
                "start": 136,
                "end": 111,
                "properties": {
                  "label": "RELATED_TO"
                },
                "color": "#673AB7",
                "thickness_factor": 1,
                "directed": true,
                "styles": {},
                "label": "RELATED_TO"
              },
              {
                "id": 1157426203745845500,
                "start": 136,
                "end": 112,
                "properties": {
                  "label": "RELATED_TO"
                },
                "color": "#673AB7",
                "thickness_factor": 1,
                "directed": true,
                "styles": {},
                "label": "RELATED_TO"
              },
              {
                "id": 1159678003559530800,
                "start": 136,
                "end": 113,
                "properties": {
                  "label": "RELATED_TO"
                },
                "color": "#673AB7",
                "thickness_factor": 1,
                "directed": true,
                "styles": {},
                "label": "RELATED_TO"
              },
              {
                "id": 1161929803373216000,
                "start": 136,
                "end": 114,
                "properties": {
                  "label": "RELATED_TO"
                },
                "color": "#673AB7",
                "thickness_factor": 1,
                "directed": true,
                "styles": {},
                "label": "RELATED_TO"
              },
              {
                "id": 1164181603186901200,
                "start": 136,
                "end": 115,
                "properties": {
                  "label": "RELATED_TO"
                },
                "color": "#673AB7",
                "thickness_factor": 1,
                "directed": true,
                "styles": {},
                "label": "RELATED_TO"
              },
              {
                "id": 1166433403000586500,
                "start": 136,
                "end": 116,
                "properties": {
                  "label": "RELATED_TO"
                },
                "color": "#673AB7",
                "thickness_factor": 1,
                "directed": true,
                "styles": {},
                "label": "RELATED_TO"
              },
              {
                "id": 1168685202814271700,
                "start": 136,
                "end": 117,
                "properties": {
                  "label": "RELATED_TO"
                },
                "color": "#673AB7",
                "thickness_factor": 1,
                "directed": true,
                "styles": {},
                "label": "RELATED_TO"
              },
              {
                "id": 1170937002627957000,
                "start": 136,
                "end": 118,
                "properties": {
                  "label": "RELATED_TO"
                },
                "color": "#673AB7",
                "thickness_factor": 1,
                "directed": true,
                "styles": {},
                "label": "RELATED_TO"
              },
              {
                "id": 1173188802441642200,
                "start": 136,
                "end": 119,
                "properties": {
                  "label": "RELATED_TO"
                },
                "color": "#673AB7",
                "thickness_factor": 1,
                "directed": true,
                "styles": {},
                "label": "RELATED_TO"
              },
              {
                "id": 1175440602255327500,
                "start": 136,
                "end": 120,
                "properties": {
                  "label": "RELATED_TO"
                },
                "color": "#673AB7",
                "thickness_factor": 1,
                "directed": true,
                "styles": {},
                "label": "RELATED_TO"
              },
              {
                "id": 1177692402069012700,
                "start": 136,
                "end": 121,
                "properties": {
                  "label": "RELATED_TO"
                },
                "color": "#673AB7",
                "thickness_factor": 1,
                "directed": true,
                "styles": {},
                "label": "RELATED_TO"
              },
              {
                "id": 1179944201882698000,
                "start": 136,
                "end": 122,
                "properties": {
                  "label": "RELATED_TO"
                },
                "color": "#673AB7",
                "thickness_factor": 1,
                "directed": true,
                "styles": {},
                "label": "RELATED_TO"
              },
              {
                "id": 1182196001696383200,
                "start": 136,
                "end": 123,
                "properties": {
                  "label": "RELATED_TO"
                },
                "color": "#673AB7",
                "thickness_factor": 1,
                "directed": true,
                "styles": {},
                "label": "RELATED_TO"
              },
              {
                "id": 1184447801510068500,
                "start": 136,
                "end": 124,
                "properties": {
                  "label": "RELATED_TO"
                },
                "color": "#673AB7",
                "thickness_factor": 1,
                "directed": true,
                "styles": {},
                "label": "RELATED_TO"
              },
              {
                "id": 1186699601323753700,
                "start": 136,
                "end": 125,
                "properties": {
                  "label": "RELATED_TO"
                },
                "color": "#673AB7",
                "thickness_factor": 1,
                "directed": true,
                "styles": {},
                "label": "RELATED_TO"
              },
              {
                "id": 1188951401137439000,
                "start": 136,
                "end": 126,
                "properties": {
                  "label": "RELATED_TO"
                },
                "color": "#673AB7",
                "thickness_factor": 1,
                "directed": true,
                "styles": {},
                "label": "RELATED_TO"
              },
              {
                "id": 1191203200951124200,
                "start": 136,
                "end": 127,
                "properties": {
                  "label": "RELATED_TO"
                },
                "color": "#673AB7",
                "thickness_factor": 1,
                "directed": true,
                "styles": {},
                "label": "RELATED_TO"
              },
              {
                "id": 1193455000764809500,
                "start": 136,
                "end": 128,
                "properties": {
                  "label": "RELATED_TO"
                },
                "color": "#673AB7",
                "thickness_factor": 1,
                "directed": true,
                "styles": {},
                "label": "RELATED_TO"
              },
              {
                "id": 6917560913478287000,
                "start": 136,
                "end": 110,
                "properties": {
                  "label": "INCLUDES"
                },
                "color": "#F44336",
                "thickness_factor": 1,
                "directed": true,
                "styles": {},
                "label": "INCLUDES"
              },
              {
                "id": 6917560913478287000,
                "start": 136,
                "end": 111,
                "properties": {
                  "label": "INCLUDES"
                },
                "color": "#F44336",
                "thickness_factor": 1,
                "directed": true,
                "styles": {},
                "label": "INCLUDES"
              },
              {
                "id": 6917560913478287000,
                "start": 136,
                "end": 112,
                "properties": {
                  "label": "INCLUDES"
                },
                "color": "#F44336",
                "thickness_factor": 1,
                "directed": true,
                "styles": {},
                "label": "INCLUDES"
              },
              {
                "id": 6917560913478287000,
                "start": 136,
                "end": 113,
                "properties": {
                  "label": "INCLUDES"
                },
                "color": "#F44336",
                "thickness_factor": 1,
                "directed": true,
                "styles": {},
                "label": "INCLUDES"
              },
              {
                "id": 6917560913478287000,
                "start": 136,
                "end": 114,
                "properties": {
                  "label": "INCLUDES"
                },
                "color": "#F44336",
                "thickness_factor": 1,
                "directed": true,
                "styles": {},
                "label": "INCLUDES"
              },
              {
                "id": 6917560913478287000,
                "start": 136,
                "end": 115,
                "properties": {
                  "label": "INCLUDES"
                },
                "color": "#F44336",
                "thickness_factor": 1,
                "directed": true,
                "styles": {},
                "label": "INCLUDES"
              },
              {
                "id": 6917560913478287000,
                "start": 136,
                "end": 116,
                "properties": {
                  "label": "INCLUDES"
                },
                "color": "#F44336",
                "thickness_factor": 1,
                "directed": true,
                "styles": {},
                "label": "INCLUDES"
              },
              {
                "id": 6917560913478287000,
                "start": 136,
                "end": 117,
                "properties": {
                  "label": "INCLUDES"
                },
                "color": "#F44336",
                "thickness_factor": 1,
                "directed": true,
                "styles": {},
                "label": "INCLUDES"
              },
              {
                "id": 6917560913478287000,
                "start": 136,
                "end": 118,
                "properties": {
                  "label": "INCLUDES"
                },
                "color": "#F44336",
                "thickness_factor": 1,
                "directed": true,
                "styles": {},
                "label": "INCLUDES"
              },
              {
                "id": 6917560913478287000,
                "start": 136,
                "end": 119,
                "properties": {
                  "label": "INCLUDES"
                },
                "color": "#F44336",
                "thickness_factor": 1,
                "directed": true,
                "styles": {},
                "label": "INCLUDES"
              },
              {
                "id": 6917560913478287000,
                "start": 136,
                "end": 120,
                "properties": {
                  "label": "INCLUDES"
                },
                "color": "#F44336",
                "thickness_factor": 1,
                "directed": true,
                "styles": {},
                "label": "INCLUDES"
              },
              {
                "id": 6917560913478287000,
                "start": 136,
                "end": 121,
                "properties": {
                  "label": "INCLUDES"
                },
                "color": "#F44336",
                "thickness_factor": 1,
                "directed": true,
                "styles": {},
                "label": "INCLUDES"
              },
              {
                "id": 6917560913478287000,
                "start": 136,
                "end": 122,
                "properties": {
                  "label": "INCLUDES"
                },
                "color": "#F44336",
                "thickness_factor": 1,
                "directed": true,
                "styles": {},
                "label": "INCLUDES"
              },
              {
                "id": 6917560913478287000,
                "start": 136,
                "end": 123,
                "properties": {
                  "label": "INCLUDES"
                },
                "color": "#F44336",
                "thickness_factor": 1,
                "directed": true,
                "styles": {},
                "label": "INCLUDES"
              },
              {
                "id": 6917560913478287000,
                "start": 136,
                "end": 124,
                "properties": {
                  "label": "INCLUDES"
                },
                "color": "#F44336",
                "thickness_factor": 1,
                "directed": true,
                "styles": {},
                "label": "INCLUDES"
              },
              {
                "id": 6917560913478287000,
                "start": 136,
                "end": 125,
                "properties": {
                  "label": "INCLUDES"
                },
                "color": "#F44336",
                "thickness_factor": 1,
                "directed": true,
                "styles": {},
                "label": "INCLUDES"
              },
              {
                "id": 6917560913478287000,
                "start": 136,
                "end": 126,
                "properties": {
                  "label": "INCLUDES"
                },
                "color": "#F44336",
                "thickness_factor": 1,
                "directed": true,
                "styles": {},
                "label": "INCLUDES"
              }
            ],
            "_graph_layout": {},
            "_highlight": [],
            "_license": {},
            "_model_module": "yfiles-jupyter-graphs",
            "_model_module_version": "^1.10.5",
            "_model_name": "GraphModel",
            "_neighborhood": {},
            "_nodes": [
              {
                "id": 70,
                "properties": {
                  "id": "Geekssql",
                  "label": "Tutorial:Technology:__Entity__"
                },
                "color": "#2196F3",
                "styles": {},
                "label": "Geekssql",
                "scale_factor": 1,
                "type": "#2196F3",
                "size": [
                  55,
                  55
                ],
                "position": [
                  0,
                  0
                ]
              },
              {
                "id": 71,
                "properties": {
                  "id": "Geeksforgeeksstack",
                  "label": "Tutorial:Technology:__Entity__"
                },
                "color": "#2196F3",
                "styles": {},
                "label": "Geeksforgeeksstack",
                "scale_factor": 1,
                "type": "#2196F3",
                "size": [
                  55,
                  55
                ],
                "position": [
                  0,
                  0
                ]
              },
              {
                "id": 72,
                "properties": {
                  "id": "Python",
                  "label": "Programming language:Language:Section:Concept:__Entity__"
                },
                "color": "#4CAF50",
                "styles": {},
                "label": "Python",
                "scale_factor": 1,
                "type": "#4CAF50",
                "size": [
                  55,
                  55
                ],
                "position": [
                  0,
                  0
                ]
              },
              {
                "id": 210,
                "properties": {
                  "id": "With Clause",
                  "label": "Concept:__Entity__"
                },
                "color": "#F44336",
                "styles": {},
                "label": "With Clause",
                "scale_factor": 1,
                "type": "#F44336",
                "size": [
                  55,
                  55
                ],
                "position": [
                  0,
                  0
                ]
              },
              {
                "id": 74,
                "properties": {
                  "id": "C++",
                  "label": "Section:Concept:Programming language:__Entity__"
                },
                "color": "#607D8B",
                "styles": {},
                "label": "C++",
                "scale_factor": 1,
                "type": "#607D8B",
                "size": [
                  55,
                  55
                ],
                "position": [
                  0,
                  0
                ]
              },
              {
                "id": 75,
                "properties": {
                  "id": "Stl",
                  "label": "Technology:__Entity__"
                },
                "color": "#673AB7",
                "styles": {},
                "label": "Stl",
                "scale_factor": 1,
                "type": "#673AB7",
                "size": [
                  55,
                  55
                ],
                "position": [
                  0,
                  0
                ]
              },
              {
                "id": 73,
                "properties": {
                  "id": "Geeksforgeeksvector",
                  "label": "Tutorial:Technology:__Entity__"
                },
                "color": "#2196F3",
                "styles": {},
                "label": "Geeksforgeeksvector",
                "scale_factor": 1,
                "type": "#2196F3",
                "size": [
                  55,
                  55
                ],
                "position": [
                  0,
                  0
                ]
              },
              {
                "id": 211,
                "properties": {
                  "id": "C++ Stl",
                  "label": "Concept:__Entity__"
                },
                "color": "#F44336",
                "styles": {},
                "label": "C++ Stl",
                "scale_factor": 1,
                "type": "#F44336",
                "size": [
                  55,
                  55
                ],
                "position": [
                  0,
                  0
                ]
              },
              {
                "id": 128,
                "properties": {
                  "id": "Scaler",
                  "label": "Platform:Category:Resource:__Entity__"
                },
                "color": "#CDDC39",
                "styles": {},
                "label": "Scaler",
                "scale_factor": 1,
                "type": "#CDDC39",
                "size": [
                  55,
                  55
                ],
                "position": [
                  0,
                  0
                ]
              },
              {
                "id": 109,
                "properties": {
                  "id": "Practice",
                  "label": "Section:Activity:Resource:__Entity__"
                },
                "color": "#9E9E9E",
                "styles": {},
                "label": "Practice",
                "scale_factor": 1,
                "type": "#9E9E9E",
                "size": [
                  55,
                  55
                ],
                "position": [
                  0,
                  0
                ]
              },
              {
                "id": 129,
                "properties": {
                  "id": "Experience Scaler",
                  "label": "Resource:__Entity__"
                },
                "color": "#9C27B0",
                "styles": {},
                "label": "Experience Scaler",
                "scale_factor": 1,
                "type": "#9C27B0",
                "size": [
                  55,
                  55
                ],
                "position": [
                  0,
                  0
                ]
              },
              {
                "id": 134,
                "properties": {
                  "id": "Resources",
                  "label": "Activity:__Entity__"
                },
                "color": "#2196F3",
                "styles": {},
                "label": "Resources",
                "scale_factor": 1,
                "type": "#2196F3",
                "size": [
                  55,
                  55
                ],
                "position": [
                  0,
                  0
                ]
              },
              {
                "id": 133,
                "properties": {
                  "id": "Interviewbit",
                  "label": "Platform:__Entity__"
                },
                "color": "#4CAF50",
                "styles": {},
                "label": "Interviewbit",
                "scale_factor": 1,
                "type": "#4CAF50",
                "size": [
                  55,
                  55
                ],
                "position": [
                  0,
                  0
                ]
              },
              {
                "id": 136,
                "properties": {
                  "id": "Experience Learning",
                  "label": "Category:__Entity__"
                },
                "color": "#F44336",
                "styles": {},
                "label": "Experience Learning",
                "scale_factor": 1,
                "type": "#F44336",
                "size": [
                  55,
                  55
                ],
                "position": [
                  0,
                  0
                ]
              },
              {
                "id": 110,
                "properties": {
                  "id": "Interview Guides",
                  "label": "Category:Resource:__Entity__"
                },
                "color": "#607D8B",
                "styles": {},
                "label": "Interview Guides",
                "scale_factor": 1,
                "type": "#607D8B",
                "size": [
                  55,
                  55
                ],
                "position": [
                  0,
                  0
                ]
              },
              {
                "id": 111,
                "properties": {
                  "id": "All Problems",
                  "label": "Category:Resource:__Entity__"
                },
                "color": "#607D8B",
                "styles": {},
                "label": "All Problems",
                "scale_factor": 1,
                "type": "#607D8B",
                "size": [
                  55,
                  55
                ],
                "position": [
                  0,
                  0
                ]
              },
              {
                "id": 112,
                "properties": {
                  "id": "Fast Track Courses",
                  "label": "Category:Resource:__Entity__"
                },
                "color": "#607D8B",
                "styles": {},
                "label": "Fast Track Courses",
                "scale_factor": 1,
                "type": "#607D8B",
                "size": [
                  55,
                  55
                ],
                "position": [
                  0,
                  0
                ]
              },
              {
                "id": 113,
                "properties": {
                  "id": "Community",
                  "label": "Category:Resource:__Entity__"
                },
                "color": "#607D8B",
                "styles": {},
                "label": "Community",
                "scale_factor": 1,
                "type": "#607D8B",
                "size": [
                  55,
                  55
                ],
                "position": [
                  0,
                  0
                ]
              },
              {
                "id": 114,
                "properties": {
                  "id": "Blog",
                  "label": "Category:Resource:__Entity__"
                },
                "color": "#607D8B",
                "styles": {},
                "label": "Blog",
                "scale_factor": 1,
                "type": "#607D8B",
                "size": [
                  55,
                  55
                ],
                "position": [
                  0,
                  0
                ]
              },
              {
                "id": 115,
                "properties": {
                  "id": "Interview Preparation Kit",
                  "label": "Category:Resource:__Entity__"
                },
                "color": "#607D8B",
                "styles": {},
                "label": "Interview Preparation Kit",
                "scale_factor": 1,
                "type": "#607D8B",
                "size": [
                  55,
                  55
                ],
                "position": [
                  0,
                  0
                ]
              },
              {
                "id": 116,
                "properties": {
                  "id": "Video Courses",
                  "label": "Category:Resource:__Entity__"
                },
                "color": "#607D8B",
                "styles": {},
                "label": "Video Courses",
                "scale_factor": 1,
                "type": "#607D8B",
                "size": [
                  55,
                  55
                ],
                "position": [
                  0,
                  0
                ]
              },
              {
                "id": 117,
                "properties": {
                  "id": "Contests",
                  "label": "Category:Resource:__Entity__"
                },
                "color": "#607D8B",
                "styles": {},
                "label": "Contests",
                "scale_factor": 1,
                "type": "#607D8B",
                "size": [
                  55,
                  55
                ],
                "position": [
                  0,
                  0
                ]
              },
              {
                "id": 118,
                "properties": {
                  "id": "Online Ide",
                  "label": "Category:Resource:__Entity__"
                },
                "color": "#607D8B",
                "styles": {},
                "label": "Online Ide",
                "scale_factor": 1,
                "type": "#607D8B",
                "size": [
                  55,
                  55
                ],
                "position": [
                  0,
                  0
                ]
              },
              {
                "id": 119,
                "properties": {
                  "id": "Online C++ Compiler",
                  "label": "Category:Resource:__Entity__"
                },
                "color": "#607D8B",
                "styles": {},
                "label": "Online C++ Compiler",
                "scale_factor": 1,
                "type": "#607D8B",
                "size": [
                  55,
                  55
                ],
                "position": [
                  0,
                  0
                ]
              },
              {
                "id": 120,
                "properties": {
                  "id": "Online C Compiler",
                  "label": "Category:Resource:__Entity__"
                },
                "color": "#607D8B",
                "styles": {},
                "label": "Online C Compiler",
                "scale_factor": 1,
                "type": "#607D8B",
                "size": [
                  55,
                  55
                ],
                "position": [
                  0,
                  0
                ]
              },
              {
                "id": 121,
                "properties": {
                  "id": "Online Python Compiler",
                  "label": "Category:Resource:__Entity__"
                },
                "color": "#607D8B",
                "styles": {},
                "label": "Online Python Compiler",
                "scale_factor": 1,
                "type": "#607D8B",
                "size": [
                  55,
                  55
                ],
                "position": [
                  0,
                  0
                ]
              },
              {
                "id": 122,
                "properties": {
                  "id": "Online Java Compiler",
                  "label": "Category:Resource:__Entity__"
                },
                "color": "#607D8B",
                "styles": {},
                "label": "Online Java Compiler",
                "scale_factor": 1,
                "type": "#607D8B",
                "size": [
                  55,
                  55
                ],
                "position": [
                  0,
                  0
                ]
              },
              {
                "id": 123,
                "properties": {
                  "id": "Online Javascript Compiler",
                  "label": "Category:Resource:__Entity__"
                },
                "color": "#607D8B",
                "styles": {},
                "label": "Online Javascript Compiler",
                "scale_factor": 1,
                "type": "#607D8B",
                "size": [
                  55,
                  55
                ],
                "position": [
                  0,
                  0
                ]
              },
              {
                "id": 124,
                "properties": {
                  "id": "Free Mock",
                  "label": "Category:Resource:__Entity__"
                },
                "color": "#607D8B",
                "styles": {},
                "label": "Free Mock",
                "scale_factor": 1,
                "type": "#607D8B",
                "size": [
                  55,
                  55
                ],
                "position": [
                  0,
                  0
                ]
              },
              {
                "id": 125,
                "properties": {
                  "id": "Free Mock Assessment",
                  "label": "Category:Resource:__Entity__"
                },
                "color": "#607D8B",
                "styles": {},
                "label": "Free Mock Assessment",
                "scale_factor": 1,
                "type": "#607D8B",
                "size": [
                  55,
                  55
                ],
                "position": [
                  0,
                  0
                ]
              },
              {
                "id": 126,
                "properties": {
                  "id": "Mock Interview",
                  "label": "Category:Resource:__Entity__"
                },
                "color": "#607D8B",
                "styles": {},
                "label": "Mock Interview",
                "scale_factor": 1,
                "type": "#607D8B",
                "size": [
                  55,
                  55
                ],
                "position": [
                  0,
                  0
                ]
              },
              {
                "id": 127,
                "properties": {
                  "id": "Events",
                  "label": "Category:Resource:__Entity__"
                },
                "color": "#607D8B",
                "styles": {},
                "label": "Events",
                "scale_factor": 1,
                "type": "#607D8B",
                "size": [
                  55,
                  55
                ],
                "position": [
                  0,
                  0
                ]
              }
            ],
            "_overview": {
              "enabled": null,
              "overview_set": false
            },
            "_selected_graph": [
              [],
              []
            ],
            "_sidebar": {
              "enabled": false,
              "start_with": null
            },
            "_view_count": null,
            "_view_module": "yfiles-jupyter-graphs",
            "_view_module_version": "^1.10.5",
            "_view_name": "GraphView",
            "layout": "IPY_MODEL_9dae961897a84a3fa3962a8eda16a3bc"
          }
        },
        "9dae961897a84a3fa3962a8eda16a3bc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": "800px",
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}